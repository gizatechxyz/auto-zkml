{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end: Airline Passenger Satisfaction\n",
    "\n",
    "In this tutorial, we will go through an end-to-end process using a real dataset. To do this, we will follow these steps:\n",
    "\n",
    "\n",
    "\n",
    "- Load training and test datasets from Kaggle.\n",
    "- Run a kernel with one of the top scores. This kernel trains a lightgbm, which is very common in Kaggle competitions.\n",
    "- Reduce the complexity of the model and measure the performance difference between the original model and the reduced model.\n",
    "\n",
    "To properly understand the functionality of serialization and model complexity reduction, before continuing with this tutorial, please review the notebooks:\n",
    "- reduce_model_complexity.ipynb\n",
    "- serialize_my_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, it is necessary to have lightgbm installed, but it is not necessary to have all packages installed to use auto_zkml. \n",
    "# For this reason, we include this cell to ensure the notebook works correctly.\n",
    "\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from auto_zkml import mcr\n",
    "from auto_zkml import serialize_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Download the data from here: https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction/code?datasetId=522275&sortBy=voteCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change ./ for your input path\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We copy the essential functionality from any kernel, for example from this one: https://www.kaggle.com/code/teejmahal20/classification-predicting-customer-satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_gender(x):\n",
    "    if x == 'Female':\n",
    "        return 1\n",
    "    elif x == 'Male':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def transform_customer_type(x):\n",
    "    if x == 'Loyal Customer':\n",
    "        return 1\n",
    "    elif x == 'disloyal Customer':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def transform_travel_type(x):\n",
    "    if x == 'Business travel':\n",
    "        return 1\n",
    "    elif x == 'Personal Travel':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def transform_class(x):\n",
    "    if x == 'Business':\n",
    "        return 2\n",
    "    elif x == 'Eco Plus':\n",
    "        return 1\n",
    "    elif x == 'Eco':\n",
    "        return 0    \n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def transform_satisfaction(x):\n",
    "    if x == 'satisfied':\n",
    "        return 1\n",
    "    elif x == 'neutral or dissatisfied':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def process_data(df):\n",
    "    df = df.drop(['Unnamed: 0', 'id'], axis = 1)\n",
    "    df['Gender'] = df['Gender'].apply(transform_gender)\n",
    "    df['Customer Type'] = df['Customer Type'].apply(transform_customer_type)\n",
    "    df['Type of Travel'] = df['Type of Travel'].apply(transform_travel_type)\n",
    "    df['Class'] = df['Class'].apply(transform_class)\n",
    "    df['satisfaction'] = df['satisfaction'].apply(transform_satisfaction)\n",
    "    df['Arrival Delay in Minutes'].fillna(df['Arrival Delay in Minutes'].median(), inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = process_data(train)\n",
    "test = process_data(test)\n",
    "\n",
    "features = ['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class',\n",
    "       'Flight Distance', 'Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
    "target = ['satisfaction']\n",
    "\n",
    "# Split into test and train\n",
    "X_train = train[features].to_numpy()\n",
    "y_train = train[target].to_numpy()\n",
    "X_test = test[features].to_numpy()\n",
    "y_test = test[target].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb ={'colsample_bytree': 0.85, \n",
    "         'max_depth': 15, \n",
    "         'min_split_gain': 0.1, \n",
    "         'n_estimators': 200, \n",
    "         'num_leaves': 50, \n",
    "         'reg_alpha': 1.2, \n",
    "         'reg_lambda': 1.2, \n",
    "         'subsample': 0.95, \n",
    "         'subsample_freq': 20,\n",
    "         'verbose' : -1}\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(**params_lgb)\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC = 0.9621874665245571\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lgb.predict(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC_AUC = {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reduce the model's complexity to see its final architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, transformer = mcr(model = model_lgb,\n",
    "                         X_train = X_train,\n",
    "                         y_train = y_train, \n",
    "                         X_eval = X_test, \n",
    "                         y_eval = y_test, \n",
    "                         eval_metric = 'auc', \n",
    "                         transform_features = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure again the performance of our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC = 0.9405872068623853\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed = transformer.transform(X_test)\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC_AUC = {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 4,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 150,\n",
       " 'n_jobs': None,\n",
       " 'num_leaves': 24,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'min_data_in_leaf': 51,\n",
       " 'feature_fraction': 0.461039390211762,\n",
       " 'bagging_fraction': 0.2799799959644911,\n",
       " 'verbose': -1,\n",
       " 'early_stopping_rounds': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 0.85,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 15,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.1,\n",
       " 'n_estimators': 200,\n",
       " 'n_jobs': None,\n",
       " 'num_leaves': 50,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 1.2,\n",
       " 'reg_lambda': 1.2,\n",
       " 'subsample': 0.95,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 20,\n",
       " 'verbose': -1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, the complexity of the model has drastically decreased. We have gone from 200 trees of depth 15 to 150 trees of depth 4. \n",
    "In addition, the model's performance has only decreased by one percent!\n",
    "\n",
    "Finally, we would serialize our reduced model in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change \"./\" for your output_path\n",
    "\n",
    "serialize_model(model_lgb, \"./\", \"lgbm_reg.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
