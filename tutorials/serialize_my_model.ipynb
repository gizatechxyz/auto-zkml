{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to serialize my model\n",
    "\n",
    "Giza_mlutils offers various functionalities that help us have a model with the necessary characteristics to be transpilable, and therefore, able to generate proofs of its inferences.\n",
    "In this case, we will talk about the serialization process, which involves saving your model in a format that can be interpreted by other Giza tools.\n",
    "\n",
    "Currently, the two supported models are XGBoost and LightGBM for both classification and regression. It is preferable that the training is done using the scikit-learn API.\n",
    "\n",
    "Let's give a very simple example of how to perform this serialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your model\n",
    "\n",
    "In this case, we will train the four types of models supported by the package: lightgbm for classification and regression, and xgboost for classification and regression.\n",
    "The datasets will be test datasets from scikit-learn: load_diabetes for regression and load_breast_cancer for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, it is necessary to have both xgboost and lightgbm installed, but it is not necessary to have all packages installed to use auto_zkml. \n",
    "# For this reason, we include this cell to ensure the notebook works correctly.\n",
    "\n",
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_estimators = 30\n",
    "max_depth = 4\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "lgbm_reg = lgbm.LGBMRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "lgbm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_estimators = 100\n",
    "max_depth = 3\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "lgbm_clf = lgbm.LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "lgbm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize It\n",
    "\n",
    "Once our models are trained, all we need to know is the outpath path (inluding the name of your model ending in \".json\") where you want to save the model.\n",
    "\n",
    "Note that it is not necessary to specify the type of model we have trained. The serializer package will understand which model it is and will apply the necessary transformations without needing to specify anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_zkml import serialize_model\n",
    "\n",
    "serialize_model(xgb_reg, \"YOUR_PATH\", \"xgb_reg.json\")\n",
    "serialize_model(lgbm_reg, \"YOUR_PATH\", \"lgbm_reg.json\")\n",
    "serialize_model(xgb_clf, \"YOUR_PATH\", \"xgb_clf.json\")\n",
    "serialize_model(lgbm_clf, \"YOUR_PATH\", \"lgbm_clf.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That simple! We now have our models saved in the correct format to use the rest of the Giza stack! But not so fast...\n",
    "In this example, the models are very simple (few trees and shallow depth), but for other problems, the optimal architecture might be much more complex and not compatible with our current technology. In this case, we will have to use another of the functionalities offered by Giza_mlutils beforehand: our model_complexity_reducer.\n",
    "\n",
    "To understand how the model_complexity_reducer (mcr) works, in this same folder you will find the notebook reduce_model_complexity.ipynb with a detailed explanation of its operation and how to run it before serializing your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
